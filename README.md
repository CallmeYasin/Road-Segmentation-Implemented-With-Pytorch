# ğŸš€ Road Seqmentation Task With A Segmentation Dataset Available!
About
=====
What is Image Segmentation? 

At its core, image segmentation is the process of partitioning a digital image into multiple segments, or "regions of interest" (ROIs). The goal is to simplify the image's representation into something more meaningful and easier to analyze.
This project is based on these main resources:
1) <b>U-Net<b> : [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597).
2) Modern computer vision with Pytorch book:[Amazon Website](https://www.amazon.com/Modern-Computer-Vision-PyTorch-comprehensive/dp/1803231335).
3) <b>Vgg16<b>:[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556).

# Let's dive into U-Net and VGG16 architecture (a quick summary)
<img src="Pics/model architecture/unet.png">

# âš™ï¸ Key Architecture Features
## 1. U-Shaped Design
- **Encoder**(Contracting Path): Left side of the "U" that captures context 
- **Decoder**(Expanding Path): Right side of the "U" that enables precise localization   
- **Bottleneck**: The bottom layer connecting encoder and decoder
## 2. Skip Connections
- The most important feature - connects corresponding layers from encoder to decoder
- Preserves spatial information lost during downsampling
- Combines high-level features with fine-grained details
## 3. Fully Convolutional
- No dense layers at the end
- Can handle input images of any size
- Outputs segmentation maps of the same spatial dimensions as input

# ğŸ’¡ Why U-Net is So Effective?
## 1. Excellent for Small Datasets
- Originally designed for medical imaging where labeled data is scarce
- Data augmentation techniques work well with its architecture
## 2. Precise Boundary Detection
- Skip connections preserve spatial details
- Perfect for tasks requiring pixel-level accuracy
## 3. Computationally Efficient
- Relatively simple architecture compared to later models
- Fast training and inference

<img src="Pics/model architecture/vgg16.png">

# âš™ï¸ Key Architecture Features
## 1. Simplicity and Uniformity
- Uses only 3Ã—3 convolutional layers throughout the entire network
- Uses only 2Ã—2 max pooling layers for downsampling
-Simple, repetitive structure makes it easy to understand and implement
## 2. 16-Layer Depth
- 13 convolutional layers + 3 fully connected layers = 16 weight layers
- One of the deepest networks of its time (2014)
## 3. Increasing Filter Depth
- Filter depth doubles after each max pooling: 64 â†’ 128 â†’ 256 â†’ 512 â†’ 512

# ğŸ’¡ Key Innovations
## 1. Small Receptive Fields
- Stacking multiple 3Ã—3 conv layers has same receptive field as larger kernels But with fewer parameters and more non-linearities

## 2. Depth Over Complexity
- Proved that network depth is crucial for performance
- Inspired even deeper architectures (ResNet, etc.)

# Theory is enogh,lets go for code

## ğŸ—ºï¸ *The path to be taken to build this project*
```
Load dataset and apply mask annotations on them and create mask images
â†“
Preproccess and visualize images and masks and put them in dataloader
â†“
Define model architecture and use vgg16 as a backbone for feature extraction
â†“
Define two metrics,IoU(Intersection over Union) and Dice score for evaluation
â†“
Train model to learn patterns and decrease loss and increase dice score
â†“
Use Fast API and use for prediction
â†“
Project has been completed!
```

## ğŸ“–*Road Project Directory*      
```
â”œâ”€â”€â”€.dist
â”œâ”€â”€â”€dataset
â”‚   â”œâ”€â”€â”€train
â”‚   â”‚   â”œâ”€â”€â”€annotations
â”‚   â”‚   â”œâ”€â”€â”€images
â”‚   â”‚   â””â”€â”€â”€masks
â”‚   â””â”€â”€â”€val
â”‚       â”œâ”€â”€â”€annotations
â”‚       â”œâ”€â”€â”€images
â”‚       â””â”€â”€â”€masks
â”œâ”€â”€â”€models
â”œâ”€â”€â”€notebook
â”œâ”€â”€â”€Pics
â”‚   â””â”€â”€â”€model architecture
â”œâ”€â”€â”€src
â”‚   â””â”€â”€â”€__pycache__
â””â”€â”€â”€test
```
# *Dataset*
## 1. ğŸ“ **Annotations**
## **What are they?**
### - Structured information about the image
### - Can be in various formats: JSON, XML, TXT, etc.
### - Contain metadata, bounding boxes, polygons, etc
## 2. ğŸ­ **Masks (Segmentation Masks)**
## **What are they?**
### - Pixel-level labels stored as images
### - Each pixel value represents a class
### - Same dimensions as the original image
### - Binary masks: 0 = background, 1 = road
## **How to use?**
```
You should download dataset from here or kaggle
â†“
1. If you downloaded dataset from kaggle you should put train images in dataset\train\images and val images in dataset\val\images and then run src\annotaions2mask.py to automaticly creat masks
2. If you downloaded dataset from here,there is no need to run src/annotations2mask.py
```
